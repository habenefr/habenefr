#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Standard
Environment settings:
\end_layout

\begin_layout Enumerate
Apriori rules - apriori algorithm takes as an input one dataframe 
\begin_inset Formula $d$
\end_inset

, and minimum values for support and confidence: 
\begin_inset Formula $Min_{support},Min_{confidence}$
\end_inset

 .
 Its output is a dataframe of rules, 
\begin_inset Formula $d_{out}$
\end_inset

.
 each rule 
\begin_inset Formula $r\in d_{out}$
\end_inset

 upholds 
\begin_inset Formula $Support(r)\geq Min_{support},Confidence(r)\geq Min_{confidence}$
\end_inset

 .
 we also might restrinct the nuber of elements in 
\begin_inset Formula $rhs(r),lhs(r)$
\end_inset

.
 
\begin_inset Formula $rhs(r)$
\end_inset

 and 
\begin_inset Formula $lhs(r)$
\end_inset

 elements are 
\begin_inset Formula $(C[v],v)$
\end_inset

 tupples where 
\begin_inset Formula $v$
\end_inset

 is the content of an entry in 
\begin_inset Formula $d$
\end_inset

 and 
\begin_inset Formula $C[v]$
\end_inset

 is the column associated with 
\begin_inset Formula $v$
\end_inset


\end_layout

\begin_layout Enumerate
Score - we add a column to 
\begin_inset Formula $d_{out}$
\end_inset

 named score.
 
\begin_inset Formula $score(r)$
\end_inset

 is used when calculating the interestingness score for a group of columns
 
\end_layout

\begin_layout Enumerate
interestingness function - for a given multiset of rows taken from 
\begin_inset Formula $d_{out}$
\end_inset

, 
\begin_inset Formula $d_{subset}$
\end_inset

, 
\begin_inset Formula $I(d_{subset})$
\end_inset

 returns a score which indicates how interesting 
\begin_inset Formula $d_{subset}$
\end_inset

 is.
 SHAP needs to get a score for each coalition in order to calculate each
 element's SHAP score.
 the score SHAP gets for each coalition in our code is the interestingness
 function results we calculate for the given coalition.
 
\end_layout

\begin_layout Enumerate
SHAP input - we are using the kerneExplainer that is a part of the SHAP
 python library.
 the kernelExplainer gets for input these 3 parameters: 
\end_layout

\begin_deeper
\begin_layout Enumerate
data - a Dataframe type parameter.
 we use 
\begin_inset Formula $d$
\end_inset

 here.
\end_layout

\begin_layout Enumerate
a target function 
\begin_inset Formula $t$
\end_inset

 - the target function can potentially be a machine learning model.
 In Our case the target function gets as an input ndarray of the current
 line SHAP is processing and returns a score for the line
\end_layout

\begin_layout Enumerate
a masker - the masker is a ndarray of shape (1, the data's columns number).
 when SHAP creates a certain coalition out of the data's columns it needs
 a mask value for each column that is not a part of the current coalition.
 these mask values are used in order for the target function not to be influence
d by these unchosen columns.
 
\end_layout

\end_deeper
\begin_layout Standard
* Sample size - since the data we use id usually very big we use a random
 sample of the data 
\end_layout

\begin_layout Standard
* Data presets - the data we are using may be unbalanced.
 this could effect the generated rules, their score, and the SHAP score.
 we might effect the data sample and its balance.
 in addition, we might want to change the columns or the actual values in
 the data - add or delete columns, change the values to be binned etc.
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
Current environment settings- * explain each choice
\end_layout

\begin_layout Enumerate
Apriori rules restrictions - support 0.05
\end_layout

\begin_layout Enumerate
\begin_inset Formula $Min_{support}=0.05$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $Min_{confidence}=0$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $d$
\end_inset

- 'adults' data set.
 (* data presets)
\end_layout

\begin_layout Enumerate
\begin_inset Formula $score(r)=lift(v)$
\end_inset


\end_layout

\begin_layout Enumerate
\begin_inset Formula $I(d_{subset})-$
\end_inset

we sort 
\begin_inset Formula $d_{subset}$
\end_inset

 by 
\begin_inset Formula $score(r)$
\end_inset

 and take top 
\begin_inset Formula $x$
\end_inset

rules.
 
\begin_inset Formula $I(d_{subset})=\sum_{i\leq x}score(r_{i})$
\end_inset


\end_layout

\begin_layout Enumerate
SHAP input - 
\end_layout

\begin_deeper
\begin_layout Enumerate
data - the alternated data from (2)
\end_layout

\begin_layout Enumerate
Target function- gets a coalition that is formed from a data row.
 The columns that are not a part of the coalition get a masked value.
 the function masks the rules dataFrame: for a given coalition, keeps the
 rules that the 'rhs' and 'lhs' elements are a subset of the coalition elements
 and their values (feature/value pairs).
 For each masked rules dataFrame it calculates the interestingness score
 and returns the score for the given input coalition.
 
\end_layout

\begin_layout Enumerate
A ndarray of '-1'
\end_layout

\end_deeper
\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Standard
**
\end_layout

\begin_layout Enumerate
Sample size - ramdon 2000 rows
\end_layout

\begin_layout Enumerate
Data presets - 
\end_layout

\begin_deeper
\begin_layout Enumerate
columns (features) - ['age', 'education-num', 'relationship', 'sex', 'hours-per-
week', 'salary'].
 these columns have numeric values.
 there is no high correletion (>0.9) between any pair of these columns.
\end_layout

\begin_layout Enumerate
values - we used bins for some of the columns.
 If a column had less than 5 different values he wasn't binned.
 If a column has more than 5 and less than 10 different values we used 3
 bins.
 if a column has more than 10 values we used 6 bins (we used for all bins
 pandas.qcut - equal-sized bins based on sample quantiles).
\end_layout

\end_deeper
\end_body
\end_document
